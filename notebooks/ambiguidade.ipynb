{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ba3fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d4ba3fd",
    "outputId": "4cb67d86-f574-4df3-bdcf-aa1768730d14"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wn\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import string\n",
    "wn.add(\"../lexico/own-pt.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca9da5",
   "metadata": {
    "id": "e5ca9da5"
   },
   "outputs": [],
   "source": [
    "def pre_processamento(frase):\n",
    "  frase = frase.lower()\n",
    "  frase = frase.translate(str.maketrans('', '', string.punctuation))\n",
    "  return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e4ff6",
   "metadata": {
    "id": "795e4ff6"
   },
   "outputs": [],
   "source": [
    "class WSD:\n",
    "    def __init__(self):\n",
    "        self.extractor = pipeline(\n",
    "            \"feature-extraction\",\n",
    "            model=\"neuralmind/bert-base-portuguese-cased\",\n",
    "            tokenizer=\"neuralmind/bert-base-portuguese-cased\",\n",
    "            framework=\"pt\"\n",
    "        )\n",
    "\n",
    "    def gerarEmbeddingSentido(self, sentido):\n",
    "        #Combinando token CLS e a media dos embeddings do sentido\n",
    "        embs = self.extractor(sentido)[0]\n",
    "        embs = np.array(embs)\n",
    "\n",
    "        embscls = embs[0]\n",
    "        embssentido = np.mean(embs[1:-1], axis=0)\n",
    "\n",
    "        return  (0.8 * embscls + 0.2 * embssentido)\n",
    "        #Usando so token CLS\n",
    "        #  embs = self.extractor(sentido)[0]\n",
    "        #  return embs[0]\n",
    "\n",
    "    def gerarEmbeddingsPalavra(self, contexto, palavra):\n",
    "        tkscontexto = self.extractor.tokenizer.tokenize(contexto)\n",
    "        tkspalavra = self.extractor.tokenizer.tokenize(palavra)\n",
    "\n",
    "        indicespalavra = self.acharPalavraContexto(tkscontexto, tkspalavra)\n",
    "\n",
    "        if not indicespalavra:\n",
    "            print(f\"Palavra '{palavra}' não encontrada no contexto\")\n",
    "            return None\n",
    "\n",
    "        embscontexto = self.extractor(contexto)[0]\n",
    "\n",
    "        indicespalavrasajustado = [i + 1 for i in indicespalavra]\n",
    "\n",
    "        embspalavra = [embscontexto[i] for i in indicespalavrasajustado]\n",
    "\n",
    "        return np.mean(embspalavra, axis=0)\n",
    "\n",
    "    def acharPalavraContexto(self, tkscontexto, tkspalavra):\n",
    "        for i in range(len(tkscontexto) - len(tkspalavra) + 1):\n",
    "            if tkscontexto[i:i+len(tkspalavra)] == tkspalavra:\n",
    "                return list(range(i, i + len(tkspalavra)))\n",
    "        return []\n",
    "\n",
    "    def compararPalavraSentido(self, contexto, palavra, sentido):\n",
    "        embspalavra = self.gerarEmbeddingsPalavra(contexto, palavra)\n",
    "        embssentido = self.gerarEmbeddingSentido(sentido)\n",
    "        if embspalavra is None:\n",
    "            return 0.0\n",
    "        return cosine_similarity([embspalavra], [embssentido])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e296a4",
   "metadata": {
    "id": "d9e296a4"
   },
   "outputs": [],
   "source": [
    "class OWNPT:\n",
    "    def getSenses(self, word):\n",
    "        senses = wn.senses(word)\n",
    "        sensesstr = []\n",
    "        for sense in senses:\n",
    "            definicao = sense.synset().definition()\n",
    "            if definicao:\n",
    "                sensesstr.append(definicao)\n",
    "        return sensesstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bbc0a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "75bbc0a3",
    "outputId": "ba17baed-8c8f-4b31-f69b-a767e3cf9f94",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wsd = WSD()\n",
    "ownpt = OWNPT()\n",
    "\n",
    "nomes_das_colunas = ['frase', 'palavra', 'sentido']\n",
    "corpus = pd.read_csv('../utils/corpus2teste_revisado_multi.csv', sep=',', on_bad_lines='skip', names=nomes_das_colunas)\n",
    "corpus['sentido'] = corpus['sentido'].apply(lambda x: x.split('|'))\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "corpus.head()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for idx, row in corpus.iterrows():\n",
    "    frase = pre_processamento(row['frase'])\n",
    "    palavra = row['palavra']\n",
    "    sentidosreais = row['sentido']\n",
    "\n",
    "    maior_sim = -1\n",
    "    melhor_sentido = None\n",
    "\n",
    "    senses = ownpt.getSenses(palavra)\n",
    "\n",
    "    for sentido_candidato in senses:\n",
    "        sim = wsd.compararPalavraSentido(frase, palavra, pre_processamento(sentido_candidato))\n",
    "        if sim is not None and sim > maior_sim:\n",
    "            maior_sim = sim\n",
    "            melhor_sentido = sentido_candidato\n",
    "\n",
    "    if melhor_sentido:\n",
    "        if melhor_sentido in sentidosreais:\n",
    "            y_true.append(melhor_sentido)\n",
    "        else:\n",
    "            y_true.append(sentidosreais[0])\n",
    "        y_pred.append(melhor_sentido)\n",
    "\n",
    "#print(\"Relatório de classificação:\")\n",
    "#print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Acurácia: {accuracy:.2f}\")\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "print(f\"Precisão (macro): {precision:.2f}\")\n",
    "print(f\"Revocação (macro): {recall:.2f}\")\n",
    "print(f\"F1-score (macro): {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4brMF29Fcn8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4brMF29Fcn8",
    "outputId": "58f6ab11-1092-4deb-ac28-96f2c7ce983a"
   },
   "outputs": [],
   "source": [
    "# Pré Processamento Lesk (remove stopwords)\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "\n",
    "def pre_processamento(frase):\n",
    "    frase = frase.lower()\n",
    "    frase = frase.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = frase.split()\n",
    "    return [w for w in tokens if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ix8UT58X_pA0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ix8UT58X_pA0",
    "outputId": "3dab81b0-2371-4e3c-f6b5-9740bdd63d13"
   },
   "outputs": [],
   "source": [
    "# Lesk\n",
    "def lesk(palavra, frase, lexico):\n",
    "    senses = lexico.getSenses(palavra)\n",
    "    contexto = set(pre_processamento(frase))\n",
    "\n",
    "    best_sense = None\n",
    "    max_overlap = -1\n",
    "\n",
    "    for sense in senses:\n",
    "        gloss_words = set(sense.lower().split())\n",
    "        overlap = len(contexto.intersection(gloss_words))\n",
    "\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = sense\n",
    "\n",
    "    return best_sense\n",
    "\n",
    "corpus = pd.read_csv('../utils/corpus2teste_revisado_multi.csv', sep=',', on_bad_lines='skip')\n",
    "corpus.columns = ['frase', 'palavra', 'sentido']\n",
    "corpus['sentido'] = corpus['sentido'].apply(lambda x: x.split('|'))\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "resultados = []\n",
    "\n",
    "for _, row in corpus.iterrows():\n",
    "    frase = row['frase']\n",
    "    palavra = row['palavra']\n",
    "    sentidosreais = row['sentido']\n",
    "\n",
    "    sentido_predito = lesk(palavra, frase, ownpt)\n",
    "    if sentido_predito:\n",
    "        if sentido_predito in sentidosreais:\n",
    "            y_true.append(sentido_predito)\n",
    "        else:\n",
    "            y_true.append(sentidosreais[0])\n",
    "        y_pred.append(sentido_predito)\n",
    "\n",
    "    resultados.append({\n",
    "            'frase': frase,\n",
    "            'palavra': palavra,\n",
    "            'sentidos_reais': ' | '.join(sentidosreais),\n",
    "            'sentido_previsto': melhor_sentido,\n",
    "            'similaridade': round(maior_sim, 4)\n",
    "        })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "#print(\"Relatório de classificação:\")\n",
    "#print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "# Cálculo das métricas\n",
    "print(\"--Lesk\")\n",
    "print(\"Acurácia:\", accuracy_score(y_true, y_pred))\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "print(f\"Precisão (macro): {precision:.2f}\")\n",
    "print(f\"Revocação (macro): {recall:.2f}\")\n",
    "print(f\"F1-score (macro): {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Iz_EgX0iEfkv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "Iz_EgX0iEfkv",
    "outputId": "62db900a-8cf4-4f84-ee2a-c3e0fe1451fe"
   },
   "outputs": [],
   "source": [
    "# Filtrar resultados onde o sentido real é diferente do previsto\n",
    "df_diferentes = df_resultados[df_resultados.apply(lambda row: row['sentido_previsto'] not in row['sentidos_reais'], axis=1)].copy()\n",
    "\n",
    "# Ordenar os resultados filtrados pela similaridade em ordem decrescente\n",
    "df_diferentes_ordenado = df_diferentes.sort_values(by='similaridade', ascending=False)\n",
    "\n",
    "# Exibir o DataFrame filtrado e ordenado\n",
    "print(\"\\nResultados onde o sentido real é diferente do previsto, ordenados pela maior similaridade:\")\n",
    "df_diferentes_ordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7c30d4-a96a-4bc0-bf97-5e92e71d643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "def selecionarSentido(contexto, palavra, wsd, ownpt):\n",
    "    doc = nlp(palavra)\n",
    "    palavra = doc[0].lemma\n",
    "    sentidos = ownpt.getSenses(palavra)\n",
    "\n",
    "    print('Palavra', palavra)\n",
    "    print('Sentidos', sentidos)\n",
    "\n",
    "    # Para ser ambígua, uma palavra precisa ter dois ou mais sentidos\n",
    "    if (sentidos == None or (sentidos != None and len(sentidos) <= 1)):\n",
    "        return None\n",
    "\n",
    "    maior_sim = -1\n",
    "    melhor_sentido = None\n",
    "\n",
    "    for sentido in sentidos:\n",
    "        sim = wsd.compararPalavraSentido(contexto, palavra, pre_processamento(sentido))\n",
    "        if sim is not None and sim > maior_sim:\n",
    "            maior_sim = sim\n",
    "            melhor_sentido = sentido\n",
    "\n",
    "    return melhor_sentido"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (Ambiguidade)",
   "language": "python",
   "name": "ambiguidade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
