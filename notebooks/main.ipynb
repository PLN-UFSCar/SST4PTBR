{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f516a953-3599-45de-9ed4-3286ef8b4383",
   "metadata": {},
   "source": [
    "# Sarcasm and ambiguity detection\n",
    "\n",
    "The objective of this notebook is to develop a system capable of automatically identifying possible cases of sarcasm and lexical ambiguity in Portuguese texts and rewriting them in a clearer and more objective way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220cf001",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "This section imports all the necessary libraries and modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2edea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import joblib\n",
    "import subprocess\n",
    "import google.generativeai as genai\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from src.rewriting import sentences, words, generate_prompt\n",
    "from src.evaluation import Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e7d9d",
   "metadata": {},
   "source": [
    "## Sarcasm detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ba290e",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "To train the model to detect sarcasm, run [_fine_tuning.ipynb_](fine_tuning.ipynb) notebook in the Google Colab environment. Follow all instructions in the notebook.\n",
    "\n",
    "After execution, save the trained model in the 'models' folder of this repository. Don't forget to unzip the .zip file, and then continue running this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af33d4d",
   "metadata": {},
   "source": [
    "### Load model\n",
    "\n",
    "This section loads the pre-trained sarcasm detection model and classifier from the models directory. The model uses SentenceTransformer for text embeddings and a logistic regression classifier for sarcasm prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98904f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"../models/finetuned_model_sarcasm\"\n",
    "CLASSIFIER_PATH = os.path.join(MODEL_DIR, \"./classifier_logreg.pkl\")\n",
    "\n",
    "def load_model():\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        raise FileNotFoundError(f\"Directory '{MODEL_DIR}' not found.\")\n",
    "    if not os.path.exists(CLASSIFIER_PATH):\n",
    "        raise FileNotFoundError(f\"Classifier '{CLASSIFIER_PATH}' not found.\")\n",
    "\n",
    "    print(\"Loading model and classifier...\")\n",
    "    model = SentenceTransformer(MODEL_DIR)\n",
    "    classifier = joblib.load(CLASSIFIER_PATH)\n",
    "    return model, classifier\n",
    "\n",
    "model, classifier = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab5bd9c",
   "metadata": {},
   "source": [
    "### Sarcasm prediction using the trained model\n",
    "\n",
    "This section contains a function that predicts sarcasm in sentences using the loaded model and classifier. It processes sentence input and returns whether sarcasm is detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8bb197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sarcasm_sentence(text, model, classifier, threshold=0.5):\n",
    "    if len(text.strip()) == 0:\n",
    "        print(\"[ERROR] Empty sentence. Try again.\")\n",
    "        return False\n",
    "    \n",
    "    embedding = model.encode([text], convert_to_tensor=True).cpu().tolist()\n",
    "    prob = classifier.predict_proba(embedding)[0][1]  # Probability of sarcasm\n",
    "\n",
    "    if prob >= threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa851ef",
   "metadata": {},
   "source": [
    "## Lexical ambiguity detection\n",
    "\n",
    "This section contains a method to detect words that have multiple meanings. It uses an external Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0d2da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ambiguity_word(word, context):\n",
    "    result = subprocess.run(\n",
    "        [\n",
    "            \"conda\", \"run\", \"-n\", \"ambiguity\", \"python\",\n",
    "            \"../src/ambiguity.py\", context, word\n",
    "        ],\n",
    "        check=True,\n",
    "        capture_output=True,\n",
    "        text=True  # To already return string instead of bytes\n",
    "    )\n",
    "\n",
    "    if (result.stdout.strip() == 'None'):\n",
    "        return [False, \"\"]\n",
    "\n",
    "    return [True, result.stdout.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5955e9c-f458-4867-813f-d081b8253e07",
   "metadata": {},
   "source": [
    "## Rewrite of phrase\n",
    "\n",
    "This section uses Google's Gemini AI model to rewrite the original text, removing detected sarcasm and resolving lexical ambiguities to produce clearer and more objective content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec2e281-1e6a-4048-aa20-b611568a883a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_KEY = ''\n",
    "genai.configure(api_key = API_KEY)\n",
    "model_gemini = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "# --- Main Program Loop ---\n",
    "\n",
    "evaluation = Evaluation()\n",
    "\n",
    "while(1):\n",
    "    print(\"\\n------------------------------------------------------\\n\")\n",
    "    print(\"Enter a text for analysis and rewrite (-1 to finish):\")\n",
    "    original_text = input()\n",
    "\n",
    "    if original_text == \"-1\":\n",
    "       break\n",
    "\n",
    "    # 1. Identification of problematic elements (sarcasm and ambiguity)\n",
    "    ambiguous_words_per_sentence = {}\n",
    "    sarcastic_sentences = []\n",
    "\n",
    "    sentences_list = sentences(original_text)\n",
    "    \n",
    "    for sentence in sentences_list:\n",
    "        if check_sarcasm_sentence(sentence, model, classifier) == True:\n",
    "            sarcastic_sentences.append(sentence)\n",
    "        \n",
    "        sentence_words_list = words(sentence)\n",
    "        ambiguous_words_sentence = []\n",
    "        for sentence_word in sentence_words_list:\n",
    "            ambiguity_result = check_ambiguity_word(sentence_word, sentence)\n",
    "            if ambiguity_result[0] == True:\n",
    "                ambiguous_words_sentence.append((sentence_word, ambiguity_result[1]))\n",
    "        \n",
    "        if ambiguous_words_sentence:\n",
    "            ambiguous_words_per_sentence[sentence] = ambiguous_words_sentence\n",
    "\n",
    "    print(\"\\n--- Detected Items for the Prompt ---\")\n",
    "    print(f\"Sarcastic sentences: {sarcastic_sentences}\")\n",
    "    print(f\"Ambiguous words per sentence: {ambiguous_words_per_sentence}\")\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "    # 2. Optimized Prompt Generation\n",
    "    final_prompt = generate_prompt(original_text, sarcastic_sentences, ambiguous_words_per_sentence)\n",
    "    \n",
    "    # 3. Generation of the Treated Text by the LLM (GEMINI)\n",
    "    print(\"\\n--- Generating text with Gemini (Hard-coded model: gemini-2.5-flash) ---\")\n",
    "    rewritten_text = model_gemini.generate_content(final_prompt).text\n",
    "\n",
    "    if rewritten_text:\n",
    "        if rewritten_text.strip().startswith(\"REWRITTEN TEXT:\"):\n",
    "            rewritten_text = rewritten_text.strip()[len(\"REWRITTEN TEXT:\"):].strip()\n",
    "        \n",
    "        if rewritten_text.startswith('\"') and rewritten_text.endswith('\"'):\n",
    "            rewritten_text = rewritten_text[1:-1].strip()\n",
    "\n",
    "        print(\"\\n--- REWRITTEN TEXT ---\")\n",
    "        print(rewritten_text)\n",
    "        print(\"-----------------------\")\n",
    "\n",
    "        print(evaluation.evaluate_rewrite(original_text, rewritten_text))\n",
    "    else:\n",
    "        print(\"\\nCould not generate the rewritten text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f3d57-9f97-4ca4-9bc4-d6123d91e3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Main)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
